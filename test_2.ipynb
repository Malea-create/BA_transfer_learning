{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.10.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python310964bittransferlearningconda9726b93461e0487db588c58d1bc36ff2",
   "display_name": "Python 3.10.9 64-bit ('transfer-learning': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TL_Regression_Methods.classify import *\n",
    "    \n",
    "def jdot_krr(X,y,Xtest,gamma_g=1, numIterBCD = 10, alpha=1,lambd=1e1, \n",
    "             method='emd',reg=1,ktype='linear'):\n",
    "    # Initializations\n",
    "    n = X.shape[0]\n",
    "    ntest = Xtest.shape[0]\n",
    "    wa=np.ones((n,))/n\n",
    "    wb=np.ones((ntest,))/ntest\n",
    "\n",
    "    # original loss\n",
    "    C0=cdist(X,Xtest,metric='sqeuclidean')\n",
    "    #print np.max(C0)\n",
    "    C0=C0/np.median(C0)\n",
    "\n",
    "    # classifier    \n",
    "    g = KRRClassifier(lambd)\n",
    "\n",
    "    # compute kernels\n",
    "    if ktype=='rbf':\n",
    "        Kt=sklearn.metrics.pairwise.rbf_kernel(Xtest,Xtest,gamma=gamma_g)\n",
    "    else:\n",
    "        Kt=sklearn.metrics.pairwise.linear_kernel(Xtest,Xtest)\n",
    "\n",
    "    C = alpha*C0#+ cdist(y,ypred,metric='sqeuclidean')\n",
    "    k=0\n",
    "    while (k<numIterBCD):# and not changeLabels:\n",
    "        k=k+1\n",
    "        if method=='sinkhorn':\n",
    "            G = ot.sinkhorn(wa,wb,C,reg)\n",
    "        if method=='emd':\n",
    "            G=  ot.emd(wa,wb,C)\n",
    "\n",
    "        Yst=ntest*G.T.dot(y)\n",
    "\n",
    "        g.fit(Kt,Yst)\n",
    "        ypred=g.predict(Kt)\n",
    "       \n",
    "        # function cost\n",
    "        fcost = cdist(y,ypred,metric='sqeuclidean')\n",
    "\n",
    "        C=alpha*C0+fcost\n",
    "            \n",
    "    return g,np.sum(G*(fcost))    \n",
    "    \n",
    "\n",
    "def jdot_svm(X,y,Xtest,  \n",
    "                      ytest=[],gamma_g=1, numIterBCD = 10, alpha=1,\n",
    "                      lambd=1e1, method='emd',reg_sink=1,ktype='linear'):\n",
    "    # Initializations\n",
    "    n = X.shape[0]\n",
    "    ntest = Xtest.shape[0]\n",
    "    wa=np.ones((n,))/n\n",
    "    wb=np.ones((ntest,))/ntest\n",
    "\n",
    "    # original loss\n",
    "    C0=cdist(X,Xtest,metric='sqeuclidean')\n",
    "\n",
    "    # classifier    \n",
    "    g = SVMClassifier(lambd)\n",
    "\n",
    "    # compute kernels\n",
    "    if ktype=='rbf':\n",
    "        Kt=sklearn.metrics.pairwise.rbf_kernel(Xtest,gamma=gamma_g)\n",
    "        #Ks=sklearn.metrics.pairwise.rbf_kernel(X,gamma=gamma_g)\n",
    "    else:\n",
    "        Kt=sklearn.metrics.pairwise.linear_kernel(Xtest)\n",
    "        #Ks=sklearn.metrics.pairwise.linear_kernel(X)\n",
    "        \n",
    "    TBR = []\n",
    "    sav_fcost = []\n",
    "    sav_totalcost = []\n",
    "\n",
    "    results = {}\n",
    "    ypred=np.zeros(y.shape)\n",
    "\n",
    "    Chinge=np.zeros(C0.shape)\n",
    "    C=alpha*C0+Chinge\n",
    "    \n",
    "    # do it only if the final labels were given\n",
    "    if len(ytest):\n",
    "        TBR.append(np.mean(ytest==np.argmax(ypred,1)+1))\n",
    "\n",
    "    k=0\n",
    "    while (k<numIterBCD):\n",
    "        k=k+1\n",
    "        if method=='sinkhorn':\n",
    "            G = ot.sinkhorn(wa,wb,C,reg_sink)\n",
    "        if method=='emd':\n",
    "            G=  ot.emd(wa,wb,C)\n",
    "\n",
    "        if k>1:\n",
    "            sav_fcost.append(np.sum(G*Chinge))\n",
    "            sav_totalcost.append(np.sum(G*(alpha*C0+Chinge)))\n",
    "\n",
    "            \n",
    "        Yst=ntest*G.T.dot((y+1)/2.)\n",
    "        #Yst=ntest*G.T.dot(y_f)\n",
    "        g.fit(Kt,Yst)\n",
    "        ypred=g.predict(Kt)\n",
    "\n",
    "        \n",
    "        Chinge=loss_hinge(y,ypred)\n",
    "        #Chinge=SVMclassifier.loss_hinge(y_f*2-1,ypred*2-1)\n",
    "        \n",
    "        C=alpha*C0+Chinge\n",
    "\n",
    "        if len(ytest):\n",
    "            TBR1=np.mean(ytest==np.argmax(ypred,1)+1)\n",
    "            TBR.append(TBR1)\n",
    "            \n",
    "\n",
    "    results['ypred']=np.argmax(ypred,1)+1\n",
    "    if len(ytest):\n",
    "        results['TBR']=TBR\n",
    "\n",
    "    results['clf']=g\n",
    "    results['G']=G\n",
    "    results['fcost']=sav_fcost\n",
    "    results['totalcost']=sav_totalcost\n",
    "    return g,results\n",
    "#\n",
    "def jdot_nn_l2(get_model,X,Y,Xtest,ytest=[],fit_params={},reset_model=True, numIterBCD = 10, alpha=1,method='emd',reg=1,nb_epoch=100,batch_size=10):\n",
    "    # get model should return a new model compiled with l2 loss\n",
    "    \n",
    "    \n",
    "    # Initializations\n",
    "    n = X.shape[0]\n",
    "    ntest = Xtest.shape[0]\n",
    "    wa=np.ones((n,))/n\n",
    "    wb=np.ones((ntest,))/ntest\n",
    "\n",
    "    # original loss\n",
    "    C0=cdist(X,Xtest,metric='sqeuclidean')\n",
    "    C0=C0/np.max(C0)\n",
    "\n",
    "    # classifier    \n",
    "    g = get_model()\n",
    "        \n",
    "    TBR = []\n",
    "    sav_fcost = []\n",
    "    sav_totalcost = []\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    #Init initial g(.)\n",
    "    g.fit(X,Y,**fit_params)\n",
    "    ypred=g.predict(Xtest)\n",
    "\n",
    "    C = alpha*C0+ cdist(Y,ypred,metric='sqeuclidean')\n",
    "\n",
    "    # do it only if the final labels were given\n",
    "    if len(ytest):\n",
    "        ydec=np.argmax(ypred,1)+1\n",
    "        TBR1=np.mean(ytest==ydec)\n",
    "        TBR.append(TBR1)\n",
    "\n",
    "    k=0\n",
    "    changeLabels=False\n",
    "    while (k<numIterBCD):# and not changeLabels:\n",
    "        k=k+1\n",
    "        if method=='sinkhorn':\n",
    "            G = ot.sinkhorn(wa,wb,C,reg)\n",
    "        if method=='emd':\n",
    "            G=  ot.emd(wa,wb,C)\n",
    "\n",
    "        Yst=ntest*G.T.dot(Y)\n",
    "        \n",
    "        if reset_model:\n",
    "            g=get_model()\n",
    "\n",
    "        g.fit(Xtest,Yst,**fit_params)\n",
    "        ypred=g.predict(Xtest)\n",
    "        \n",
    "        # function cost\n",
    "        fcost = cdist(Y,ypred,metric='sqeuclidean')\n",
    "        #pl.figure()\n",
    "        #pl.imshow(fcost)\n",
    "        #pl.show()\n",
    "\n",
    "        C=alpha*C0+fcost\n",
    "\n",
    "        ydec_tmp=np.argmax(ypred,1)+1\n",
    "        if k>1:\n",
    "            changeLabels=np.all(ydec_tmp==ydec)\n",
    "            sav_fcost.append(np.sum(G*fcost))\n",
    "            sav_totalcost.append(np.sum(G*(alpha*C0+fcost)))\n",
    "\n",
    "        ydec=ydec_tmp\n",
    "        if len(ytest):\n",
    "            TBR1=np.mean((ytest-ypred)**2)\n",
    "            TBR.append(TBR1)\n",
    "            \n",
    "    results['ypred0']=ypred\n",
    "    results['ypred']=np.argmax(ypred,1)+1\n",
    "    if len(ytest):\n",
    "        results['mse']=TBR\n",
    "    results['clf']=g\n",
    "    results['fcost']=sav_fcost\n",
    "    results['totalcost']=sav_totalcost\n",
    "    return g,results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Column: 1.00 has the highest correlation with the target: 0.49783558206163886\nDf has been split into 3 equal parts:  (334, 9) (334, 9) (334, 9)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split according to distribution\n",
    "\n",
    "df = pd.read_csv(\"data\\ICS\\Concrete_Data_2.csv\", \";\")\n",
    "df= df.fillna(0)\n",
    "\n",
    "# Calculate Correlation between coloumns \n",
    "corr_values = []\n",
    "highest_corr = 0\n",
    "highest_col = 0\n",
    "\n",
    "for col in df:\n",
    "    corr = df[\"9.00\"].corr(df[col])\n",
    "    corr_values.append(corr)\n",
    "    if corr >= max(corr_values) and corr < 1.0:\n",
    "        highest_corr = corr\n",
    "        highest_col = col\n",
    "    #print(\"Correlation between the target and \"+ str(col) + \" : \" + str(corr))\n",
    "    #print(highest_corr)\n",
    "\n",
    "# Selecto Corr >= 0,4 and sort data accordingly \n",
    "print (\"Column: \"+str(highest_col)+ \" has the highest correlation with the target: \" + str(highest_corr))\n",
    "df = df.sort_values(by=[highest_col])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split df in 3 equal parts\n",
    "split = int(len(df[:1000])/3)\n",
    "df_1 = df.loc[0:split,:]\n",
    "df_2 = df.loc[split:split*2,:]\n",
    "df_3 = df.loc[split*2:split*3,:]\n",
    "print(\"Df has been split into 3 equal parts: \",df_1.shape,df_2.shape,df_3.shape)\n",
    "\n",
    "df_src = df_1 #.append(df_2)\n",
    "#print(df_src.head(), df_src.shape)\n",
    "\n",
    "df_tar = df_2\n",
    "#print(df_tar.head(), df_tar.shape)\n",
    "\n",
    "# source\n",
    "Xs = df_src.iloc[:,:-1]\n",
    "Ys = df_src.iloc[:,-1]\n",
    "\n",
    "# target_train\n",
    "Xt = df_tar.iloc[:,:-1]\n",
    "Yt = df_tar.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "XA must be a 2-dimensional array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m C\u001b[38;5;241m=\u001b[39malpha\u001b[38;5;241m*\u001b[39mC0\u001b[38;5;241m+\u001b[39mfcost\n\u001b[0;32m     75\u001b[0m G0\u001b[38;5;241m=\u001b[39mot\u001b[38;5;241m.\u001b[39memd(ot\u001b[38;5;241m.\u001b[39munif(n),ot\u001b[38;5;241m.\u001b[39munif(n),C)\n\u001b[1;32m---> 77\u001b[0m model,loss \u001b[38;5;241m=\u001b[39m \u001b[43mjdot_krr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mYs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumIterBCD\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambd0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mktype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m K\u001b[38;5;241m=\u001b[39msklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise\u001b[38;5;241m.\u001b[39mrbf_kernel(Xt,Xt,gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m     80\u001b[0m Kvisu\u001b[38;5;241m=\u001b[39msklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise\u001b[38;5;241m.\u001b[39mrbf_kernel(xvisu\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)),Xt,gamma\u001b[38;5;241m=\u001b[39mgamma)\n",
      "Cell \u001b[1;32mIn[18], line 40\u001b[0m, in \u001b[0;36mjdot_krr\u001b[1;34m(X, y, Xtest, gamma_g, numIterBCD, alpha, lambd, method, reg, ktype)\u001b[0m\n\u001b[0;32m     37\u001b[0m     ypred\u001b[38;5;241m=\u001b[39mg\u001b[38;5;241m.\u001b[39mpredict(Kt)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# function cost\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     fcost \u001b[38;5;241m=\u001b[39m \u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mypred\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msqeuclidean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     C\u001b[38;5;241m=\u001b[39malpha\u001b[38;5;241m*\u001b[39mC0\u001b[38;5;241m+\u001b[39mfcost\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m g,np\u001b[38;5;241m.\u001b[39msum(G\u001b[38;5;241m*\u001b[39m(fcost))\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\transfer-learning\\lib\\site-packages\\scipy\\spatial\\distance.py:2916\u001b[0m, in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2913\u001b[0m sB \u001b[38;5;241m=\u001b[39m XB\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   2915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2916\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXA must be a 2-dimensional array.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sB) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   2918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXB must be a 2-dimensional array.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: XA must be a 2-dimensional array."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "#from TL_Regression_Methods.JDOT import *\n",
    "\n",
    "#from sklearn import datasets\n",
    "import sklearn\n",
    "from scipy.spatial.distance import cdist \n",
    "import ot\n",
    "\n",
    "\n",
    "#%% data generation\n",
    "\n",
    "seed=1985\n",
    "np.random.seed(seed)\n",
    "\n",
    "n = 200\n",
    "ntest=200\n",
    "\n",
    "\n",
    "def get_data(n,ntest):\n",
    "\n",
    "    n2=int(n/2)\n",
    "    sigma=0.05\n",
    "    \n",
    "    xs=np.random.randn(n,1)+2\n",
    "    xs[:n2,:]-=4\n",
    "    ys=sigma*np.random.randn(n,1)+np.sin(xs/2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    xt=np.random.randn(n,1)+2\n",
    "    xt[:n2,:]/=2 \n",
    "    xt[:n2,:]-=3\n",
    "      \n",
    "    yt=sigma*np.random.randn(n,1)+np.sin(xt/2)\n",
    "    xt+=2\n",
    "    \n",
    "    return xs,ys,xt,yt\n",
    "\n",
    "xs,ys,xt,yt=get_data(n,ntest)\n",
    "\n",
    "\n",
    "fs_s = lambda x: np.sin(x/2)\n",
    "fs_t = lambda x: np.sin((x-2)/2)\n",
    "\n",
    "                       \n",
    "xvisu=np.linspace(-4,6.5,100)\n",
    "\n",
    "pl.figure(1)\n",
    "pl.clf()\n",
    "\n",
    "pl.subplot()\n",
    "pl.scatter(xs,ys,label='Source samples',edgecolors='k')\n",
    "pl.scatter(xt,yt,label='Target samples',edgecolors='k')\n",
    "pl.plot(xvisu,fs_s(xvisu),'b',label='Source model')\n",
    "pl.plot(xvisu,fs_t(xvisu),'g',label='Target model')\n",
    "pl.xlabel('x')\n",
    "\n",
    "pl.ylabel('y')\n",
    "pl.legend()\n",
    "pl.title('Toy regression example')\n",
    "#pl.savefig('imgs/visu_data_reg.eps')\n",
    "\n",
    "#%% TLOT\n",
    "lambd0=1e1\n",
    "itermax=15\n",
    "gamma=1e-1\n",
    "alpha=1e0/4\n",
    "C0=cdist(xs,xt,metric='sqeuclidean')\n",
    "#print np.max(C0)\n",
    "C0=C0/np.median(C0)\n",
    "fcost = cdist(ys,yt,metric='sqeuclidean')\n",
    "C=alpha*C0+fcost\n",
    "G0=ot.emd(ot.unif(n),ot.unif(n),C)\n",
    "\n",
    "model,loss = jdot_krr(Xs,Ys,Xt,gamma_g=gamma,numIterBCD = 10, alpha=alpha, lambd=lambd0,ktype='rbf')\n",
    "\n",
    "K=sklearn.metrics.pairwise.rbf_kernel(Xt,Xt,gamma=gamma)\n",
    "Kvisu=sklearn.metrics.pairwise.rbf_kernel(xvisu.reshape((-1,1)),Xt,gamma=gamma)\n",
    "ypred=model.predict(Kvisu)\n",
    "ypred0=model.predict(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}